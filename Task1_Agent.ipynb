{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "943be521",
   "metadata": {},
   "source": [
    "## Documentation Quality Analyzer\n",
    "\n",
    "This script analyzes technical documentation quality using AI and readability metrics. It's designed for content teams to evaluate documentation against key quality dimensions and Microsoft Style Guide principles.\n",
    "\n",
    "### Technologies Used\n",
    "\n",
    "1. **Google Gemini API** (`gemini-1.5-flash`)\n",
    "   - AI-powered analysis of documentation content\n",
    "   - Evaluates readability, structure, completeness, and style compliance\n",
    "   - Processes text in efficient JSON format\n",
    "\n",
    "2. **Text Processing Libraries**\n",
    "   - `markdown`: Converts MD to plain text\n",
    "   - `BeautifulSoup`: HTML content cleaning\n",
    "   - `frontmatter`: Handles YAML metadata in MD files\n",
    "   - `textstat`: Readability metrics (not implemented but prepped for extension)\n",
    "\n",
    "3. **Core Python Modules**\n",
    "   - `re`: Pattern matching for content cleaning\n",
    "   - `json`: Structured report generation\n",
    "   - `os`: File system operations\n",
    "   - `time`: API rate limiting\n",
    "\n",
    "### Why This Approach?\n",
    "\n",
    "The implementation focuses on:\n",
    "- **Efficiency**: \n",
    "  - Uses lightweight Gemini Flash model\n",
    "  - Combines analysis dimensions in single API call\n",
    "  - Implements 1-sec rate limiting for free tier\n",
    "- **Accuracy**:\n",
    "  - Advanced content preprocessing\n",
    "  - JSON response validation/repair\n",
    "  - Context-aware heading markers\n",
    "- **Actionability**:\n",
    "  - Structured suggestions for writers\n",
    "  - Microsoft Style Guide compliance checks\n",
    "  - Focus on non-technical readability\n",
    "- **Scalability**:\n",
    "  - Modular design for new analysis types\n",
    "  - Automatic filename handling\n",
    "  - Batch processing ready\n",
    "\n",
    "### Analysis Dimensions\n",
    "\n",
    "1. **Readability**: \n",
    "   - Jargon usage\n",
    "   - Sentence complexity\n",
    "   - Non-technical audience suitability\n",
    "\n",
    "2. **Structure**:\n",
    "   - Heading hierarchy\n",
    "   - Logical flow\n",
    "   - Paragraph length optimization\n",
    "\n",
    "3. **Completeness**:\n",
    "   - Implementation details\n",
    "   - Example quality\n",
    "   - Coverage depth\n",
    "\n",
    "4. **Style Compliance**:\n",
    "   - Microsoft Voice guidelines\n",
    "   - Action-oriented language\n",
    "   - Clarity standards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff64b0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis...\n",
      "\n",
      "Analyzing preprocessed_data/preprocessed_web_sdk_overview.md...\n",
      "Report saved to: ./Outputs_Task1\\analysis_360061108111.json\n",
      "\n",
      "Analyzing preprocessed_data/preprocessed_getting_started_with_react_native_sdk.md...\n",
      "Report saved to: ./Outputs_Task1\\analysis_22105190881044.json\n",
      "\n",
      "Analysis complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import textstat\n",
    "import markdown\n",
    "import google.generativeai as genai\n",
    "from bs4 import BeautifulSoup\n",
    "import frontmatter\n",
    "from urllib.parse import urlparse\n",
    "import time\n",
    "\n",
    "GEMINI_API_KEY = \"Secret...\"  # Replace with your actual API key\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "\n",
    "# I used an efficient model for free tier\n",
    "GEMINI_MODEL = \"gemini-1.5-flash\"\n",
    "\n",
    "def preprocess_md(file_path):\n",
    "    \"\"\"Extract and clean Markdown content\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        # Handle frontmatter if exists\n",
    "        if content.startswith('---'):\n",
    "            post = frontmatter.loads(content)\n",
    "            content = post.content\n",
    "        \n",
    "        # Remove code blocks and images\n",
    "        content = re.sub(r'```.*?```', '', content, flags=re.DOTALL)\n",
    "        content = re.sub(r'\\!\\[.*?\\]\\(.*?\\)', '', content)\n",
    "        \n",
    "        # Convert markdown to plain text with proper heading formatting\n",
    "        text = markdown.markdown(content)\n",
    "        \n",
    "        # Clean HTML tags and excessive whitespace\n",
    "        text = re.sub(r'<[^>]+>', '', text)\n",
    "        text = re.sub(r'\\n{3,}', '\\n\\n', text).strip()\n",
    "        \n",
    "        # Add structure markers for headings\n",
    "        text = re.sub(r'\\n(#+)\\s+(.*?)\\n', r'\\nHEADING_\\1: \\2\\n', text)\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "        return \"\"\n",
    "\n",
    "def url_to_filename(url):\n",
    "    \"\"\"Create safe filename from URL\"\"\"\n",
    "    parsed = urlparse(url)\n",
    "    path = parsed.path.strip('/')\n",
    "    # Extract article ID if exists\n",
    "    article_id = re.search(r'articles/(\\d+)', path)\n",
    "    if article_id:\n",
    "        return f\"analysis_{article_id.group(1)}.json\"\n",
    "    # Fallback to last path segment\n",
    "    return f\"analysis_{path.split('/')[-1]}.json\"\n",
    "\n",
    "class DocumentationAnalyzer:\n",
    "    def __init__(self, model=GEMINI_MODEL):\n",
    "        self.model = genai.GenerativeModel(model)\n",
    "        self.last_call_time = 0\n",
    "    \n",
    "    def _clean_json_response(self, response_text):\n",
    "        \"\"\"Clean and parse JSON response from Gemini\"\"\"\n",
    "        try:\n",
    "            # Remove markdown code block markers if present\n",
    "            if response_text.startswith(\"```json\"):\n",
    "                response_text = response_text[7:]\n",
    "            if response_text.endswith(\"```\"):\n",
    "                response_text = response_text[:-3]\n",
    "                \n",
    "            return json.loads(response_text.strip())\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Fixing malformed JSON response...\")\n",
    "            # Attempt to repair common JSON issues\n",
    "            response_text = re.sub(r',\\s*}', '}', response_text)  # Trailing commas\n",
    "            response_text = re.sub(r',\\s*]', ']', response_text)\n",
    "            response_text = re.sub(r'(\\w+):', r'\"\\1\":', response_text)  # Unquoted keys\n",
    "            return json.loads(response_text)\n",
    "\n",
    "    def _llm_analysis(self, prompt, text):\n",
    "        \"\"\"Gemini analysis with rate limiting\"\"\"\n",
    "        # Enforce 60 RPM free tier limit (1 call/second)\n",
    "        elapsed = time.time() - self.last_call_time\n",
    "        if elapsed < 1.0:\n",
    "            time.sleep(1.0 - elapsed)\n",
    "        \n",
    "        try:\n",
    "            # Combine analysis types to reduce API calls\n",
    "            combined_prompt = f\"\"\"Analyze documentation content for the following aspects:\n",
    "1. READABILITY (for non-technical marketers): Jargon usage, sentence complexity\n",
    "2. STRUCTURE: Heading organization, logical flow, paragraph length\n",
    "3. COMPLETENESS: Implementation details, example quality\n",
    "4. STYLE: Microsoft Style Guide compliance (voice, clarity, action-oriented)\n",
    "\n",
    "Provide JSON output with these keys:\n",
    "- \"readability\": {{\"assessment\": \"summary\", \"suggestions\": [\"list\"]}}\n",
    "- \"structure\": {{\"assessment\": \"summary\", \"suggestions\": [\"list\"]}}\n",
    "- \"completeness\": {{\"assessment\": \"summary\", \"suggestions\": [\"list\"]}}\n",
    "- \"style\": {{\"assessment\": \"summary\", \"suggestions\": [\"list\"]}}\n",
    "\n",
    "CONTENT:\n",
    "{text[:30000]}\"\"\"  # Stay within context limits\n",
    "            \n",
    "            response = self.model.generate_content(\n",
    "                combined_prompt,\n",
    "                generation_config=genai.types.GenerationConfig(\n",
    "                    temperature=0.2,\n",
    "                    max_output_tokens=2000,\n",
    "                    response_mime_type=\"application/json\"\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            self.last_call_time = time.time()\n",
    "            return self._clean_json_response(response.text)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Gemini API error: {str(e)}\")\n",
    "            return {\"error\": str(e)}\n",
    "\n",
    "    def analyze(self, url, file_path):\n",
    "        \"\"\"Efficient analysis workflow\"\"\"\n",
    "        text = preprocess_md(file_path)\n",
    "        if not text or len(text) < 100:\n",
    "            return {\"error\": \"Insufficient text content for analysis\"}\n",
    "        \n",
    "        return {\n",
    "            \"url\": url,\n",
    "            \"results\": self._llm_analysis(None, text)\n",
    "        }\n",
    "\n",
    "    def save_report(self, results, output_file):\n",
    "        \"\"\"Save structured report\"\"\"\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "        print(f\"Report saved to: {output_file}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function with predefined file details\"\"\"\n",
    "    analyzer = DocumentationAnalyzer()\n",
    "    \n",
    "    # Predefined document details\n",
    "    file1 = \"preprocessed_data/preprocessed_web_sdk_overview.md\"\n",
    "    url1 = \"https://developers.moengage.com/hc/en-us/articles/360061108111-Web-SDK-Overview#h_01H9G1YMFWVN61PKBDN0MGAJWG\"\n",
    "    \n",
    "    file2 = \"preprocessed_data/preprocessed_getting_started_with_react_native_sdk.md\"\n",
    "    url2 = \"https://developers.moengage.com/hc/en-us/articles/22105190881044-Getting-Started-with-React-Native-SDK#h_01HEJAHP5W49AASNSHF5614AHP\"\n",
    "    \n",
    "    output_dir = \"./Outputs_Task1\"  # Output directory\n",
    "    \n",
    "    # Create output directory if needed\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Process documents\n",
    "    print(\"Starting analysis...\\n\")\n",
    "    \n",
    "    print(f\"Analyzing {file1}...\")\n",
    "    report1 = analyzer.analyze(url1, file1)\n",
    "    analyzer.save_report(report1, os.path.join(output_dir, url_to_filename(url1)))\n",
    "    \n",
    "    print(f\"\\nAnalyzing {file2}...\")\n",
    "    report2 = analyzer.analyze(url2, file2)\n",
    "    analyzer.save_report(report2, os.path.join(output_dir, url_to_filename(url2)))\n",
    "    \n",
    "    print(\"\\nAnalysis complete!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
